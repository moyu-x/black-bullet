## 基础

我们可以把消息队列比作是一个存放消息的容器，当我们需要使用消息的时候可以取出消息供自己使用

### 好处

使用消息队列的好处：

1. 通过异步处理提高系统性能
2. 降低系统耦合性

消息队列使用发布-订阅模式工作，生产者发布消息，一个或多个消费者订阅消息。为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息。

### 用途

1. 异步
2. 解耦
3. 削峰

### 问题

1. 系统可用性降低
2. 系统复杂性提高
3. 一致性问题

## JMS

Java Message Service API是一个消息服务的标准（规范），运行应用程序组件给予J2EE平台创建、发送、接收和读取消息。它是分布式通信耦合度变低，消息服务更加可靠以及异步性

### 消息模型

1. 点到点模型：使用队列作为消息通信载体，满足生产者消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。
2. 发布订阅模型：发布订阅模型使用Topic作为消息通信载体。发布者发布消息后，该消息通过Topic发送给所有订阅者，在一条消息广播之后才订阅的用户则是收不到该消息的

### 五种不同的消息正文格式

- StreamMessage
- MapMessage
- TextMessage
- ObjectMessage
- BytesMessage

## AMQP

Advanced Message Queuing Protocol提供统一消息服务的应用层标准。

### 与JMS的对比

- AMQP为消息定义了线路层的协议，而JMS所定义的是Java API规范。
- JMS支持TextMessage、MapMessage等复杂消息类型，而AMQP仅支持`byte[]`消息类型，复杂的消息需要序列化
- 由于Exchange提供路由算法，AMQP可以提供多样化的路由方式来传递消息到消息队列

## RabbitMQ

### 核心概念

- Product
- Consumer
- Exchange：用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给 Producter，或许会被直接丢弃掉。有四种类型：
    1. direct（默认）：消息路由到那些Bindingkey与RoutingKey完全匹配的Queue中
    2. fanout：把所有发送到该Exchange的消息路由到所有与它绑定的Queue中，常用来广播消息
    3. topic
    4. headers（不推荐）：headers类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配
- Queue：用来保存消息直到发送给消费者。消息只能存储在Queue中，多个消费者可以订阅同一个队列
- Broker：消息中间件的服务节点

消息有消息头和消息体组成，消息体可被称为Payload，消息体是不透明的，而消息头由一系列可选属性组成。

生产者将消息发给交换器的时候，一般会指定一个RoutingKey，用来指定这个消息的路由规则，而RoutingKey需要与交换器类型和BingKey联合使用才能生效

RabbitMQ中通过Bingding讲Exchange与Queue关联起来，在绑定的时候一般会指定一个BindingKey

### 高可用

其是基于主从模式做的高可用，有三种模式：

1. 单机模式
2. 普通集群模式（无高可用性）：在多台机器上启动多个RabbitMQ实例，创建的Queue，只会放在一个RabbitMQ实例上，但是每个实例都同步 queue的元数据。消费的时候，如果实际上连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来
3. 镜像集群模式（高可用性）：在镜像集群模式下创建的Queue，无论元数据还是queue的消息都会存在多个实例上。

### 保证数据不丢失

**生产者丢数据**

1. 可以选择使用RabbitMQ提供的事务功能，但是这样吞吐量会下来，太消耗性能
2. 一般开启confirm模式：在生产者开启confirm模式，每次写消息都会分配一个唯一id，成功写入则返回ack消息，写入失败返回nack消息，并且可以根据这个id自己维护状态，超时未收到ack或nack可以尝试重试机制

事务机制是阻塞的，confirm模式是异步的

**RabbitMQ丢失数据**

可以开启RabbitMQ的持久化机制，开启后写入的消息会持久化到硬盘。

步骤：

1. 创建Queue时将其设置为持久化
2. 发送消息是将消息的`delivery`设置为2

**消费端丢失数据**

关闭RabbitMQ的自动ack，使用api来手动完成ack

## Kafka

由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。

流平台具有三个关键功能：

1. 消息队列
2. 容错的持久方式存储记录消息流
3. 流式处理平台

应用场景：

1. 消息队列
2. 数据处理

### 队列模型

使用队列作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时

问题：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完成的消息内容，这种队列模型不好解决了。

### 发布-订阅模型

发布订阅模型（Pub-Sub）使用主题（Topic）作为消息通信载体，类似于广播模式；发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。

在发布-订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布-订阅模型在功能层面上是可以兼容队列模型的。

Kafka 采用的就是发布-订阅模型。

### 保证消息不丢失

- 生产者丢失消息情况：使用重试，重试次数设置为3比较合适
- 消息者丢失消息的情况：和Kafka的offset有关，自动提交offset，当消费者拿到消息准备消费时Kafka崩溃，消息实际上没被消费，但是offset被手动提交，这个时候就会丢失消息。解决办法手动关闭闭自动提交offset，每次在真正消费完消息之后之后再自己手动提交offset
- Kafka丢失消息：leader副本所在的broker突然挂了，那么就要从follower副本中重新选出一个leader，leader中要是一些数据没同步，这个时候就会造成数据丢失
    1. 设置`acks=all`
    2. 设置`replication.factor >= 3`
    3. 设置`min.insync.replicas > 1`
    4. 设置`unclean.leader.election.enable = false`
# 优缺点

## 优点

消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：**解耦**、**异步**、**削峰**。一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。

## 缺点

1. 系统可用性降低
2. 系统复杂度提高
3. 一致性问题

## 常见消息队列对比

[无标题](https://www.notion.so/ff3e158771d840bea38f86b1301aee9b?pvs=21)

# RabbitMQ

RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

## 部署模式

### 普通集群模式

普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你

**创建的 queue，只会放在一个 RabbitMQ 实例上**

，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。

![[assets/a7fae78911dec71bdc453c4d8262d1b7_MD5.jpg]]

这个方案没有什么所谓的高可用，主要目标是提高吞吐量

### 镜像集群模式

这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会

**存在于多个实例上**

，就是说，每个 RabbitMQ 节点都有这个 queue 的一个

**完整镜像**

，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把

**消息同步**

到多个实例的 queue 上。

![[assets/56e15d14ca1f9dab94a775b9f22049dc_MD5.jpg]]

## 丢数据

![[assets/9965f0effbd8577c1352fd8428fa6017_MD5.jpg]]

丢数据

![[assets/2e63e0aed3c87eef94f23cf3d9c03e21_MD5.jpg]]

image.png

### 生产者丢数据

1. 可以选择用 RabbitMQ 提供的事务功能，就是生产者**发送数据之前**开启 RabbitMQ 事务`channel.txSelect`，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务`channel.txRollback`，然后重试发送消息；如果收到了消息，那么可以提交事务`channel.txCommit`。但是问题是，RabbitMQ 事务机制（同步）一搞，基本上**吞吐量会下来，因为太耗性能**。
2. 所以一般来说，如果你要确保说写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。所以一般在生产者这块**避免数据丢失**，都是用 `confirm` 机制的。

### RabbitMQ 弄丢了数据

1. 创建 Queue 的时候将其设置为持久化
2. 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2，这个时候就会将数据持久化到磁盘上

这个必须是了同时设置了这两个才行

### 消费者丢了数据

关闭自动 ack，使用手动的 ACK

## 顺序保证

拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

# Kafka

Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。这就是**天然的分布式消息队列**，就是说一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。

## 高可用

Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言。比如说，我们假设创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的 1/3 的数据就丢了，因此这个是做不到高可用的。

![[assets/5193c517e570c05b7a3bbc6d48c21c9b_MD5.jpg]]

高可用

Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？很简单，**要是你可以随意读写每个 follower，那么就要 care 数据一致性的问题**，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。

![[assets/4adc427e0e60623af77fa53e1905bb72_MD5.jpg]]

image.png

这么搞，就有所谓的**高可用性**了，因为如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。

**写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

**消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

## 丢数据

### 消费者丢数据

唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边**自动提交了 offset**，让 Kafka 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。这个时候就关闭自动提交 offset，改为手动提交 offset。这会导致重复消费，这个时候做到幂等就行了。

### Kafka 丢数据

这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。所以此时一般是要求起码设置如下 4 个参数：

- 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
- 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
- 在 producer 端设置 `acks=all`：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
- 在 producer 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。

### 生产者

如果按照上述的思路设置了 `acks=all`，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

## 顺序保证

写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

# 重复消费

其实重复消费不可怕，可怕的是你没考虑到重复消费之后，**怎么保证幂等性**。幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，**不能出错**。几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。