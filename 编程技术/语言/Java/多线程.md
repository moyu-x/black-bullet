同类的多个线程共享堆的方法区，但每个线程拥有自己的程序计数器、虚拟机栈和本地方法栈。

![[assets/05fcb4d2459607774bde22345799b7a7_MD5.jpeg]]

死锁的形成一定能在状态上找到一个环，可以参考死锁产生的必要条件：1. 互斥条件；2.请求与保持；3.不剥夺条件；4.循环等等

从底层看sleep是将线程退出临界区，他一定会再次进入临界区，所以不会释放锁；而wait方法也是退出执行，但是他不一定会再次使用，如不释放锁则会造成死锁，所以要将锁释放；其主要区别是再与语义实现上。

用start方法开启线程会使线程进入就绪状态，而run从语义上是立即执行，相当于直接在当前线程执行代码。

`Runnable` 接口不会返回结果或抛出检查异常，但是`Callable`接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用`Runnable`接口，这样代码看起来会更加简洁。工具类`Executors`可以实现`Runnable`对象和`Callable`对象之间的相互转换。

查看`AbstractExecutorService`接口的submit方法，可以看到调用`newTaskFor`的方法返回了一个`FeautreTask`对象，而execute则是执行相关代码

## synchronized

synchronizied早期属于重量级锁，其使用监视器锁进行实现，监视器锁利用系统的信号量实现，所以在使用过程中必然包含大量的上下文切换操作。

其在修饰静态方法时，由于静态方法属于类，所以实际是给类上了锁。

### 同步语句块

![[assets/606d7033979c8e78e07462d0830ad920_MD5.jpeg]]

通过简单的demo，并且进行反编译class文件，我们可以看到明显的两个指令`monitorenter`和`monitorexit`，这中间包裹的就是同步代码块。

### 修饰方法

![[assets/5544adbd6a7308bf720ae01e6de8abdf_MD5.jpeg]]

使用`ACC_SYNCHRONIZED`来表明这是一个同步代码块，在调用方法时就开始同步

### 和ReentrantLock的比较

1. 两个都是可重入锁，也就是不会堵塞其他线程获取锁
2. synchronized依赖于jvm实现，从class文件可以看出；`ReentrantLock`依赖于API，灵活度较高，所以可以实现
    1. `ReentrantLock`提供了能够中断等待锁的线程机制
    2. `ReentrantLock`可以构建是公平锁还是非公平锁
    3. 可以选择性通知，通过`condition`类可以很好实现选择性通知

### 和volatile对比

首选我们得先确定volatile不是一个锁，只是一个同步语义操作，目的是为了防止含有此修饰操作的指令重排，所以在没有锁的特性的情况下会有部分锁同步的特性，所以具体的有一下不同

1. `volatile`是线程同步的轻量级别实现，性能比`synchronized`好，但是不能替代，毕竟场景不一样
2. 由于只是一个同步操作，所以不会发生阻塞（毕竟底层只是防止了指令的重排），而`synchronized`是一个锁，所以会发生阻塞
3. `volatile`是同步语义操作，所以只能保证可见性，但是不能保证原子性
4. `volatile`防止了指令重排，虽然重线程层面是多线程操作，但是从内部操作看，其防止指令重排强制线程对数据的访问变成有序的，所以只能作用于变量上面；而`synchronized`是一个锁操作，其虽然依赖于系统的信号量实现，但是其目的是保证资源同步，相当于强制要求多个线程对资源访问是有序的。

## ThreadLocal

从类注释中，可以得到其提供了一个线程访问局部变量的工具，每个访问变量的线程都有自己独立初始化的变量副本。实例通常放在与之管理的私有化的静态域中。当每个变量访问结束后，这个变量都会被回收，除非还有其他引用没有结束。

### 原理

对于其如何发挥作用的，得先从`get`方法看起，在获取当前线程后，用`getMap`来获取具体的线程实例，通过`getMap`方法，我们来到了`Thread`类中维护的`threadLocals`变量，这个时候就会发现这个地方维护了一个定制化的map来存数据，用`this`来得到当前线程的变量副本，这里的this表示的是当前线程对`threadlocal`的引用，不为空就返回。为空就说明是第一次调用，去进行初始化操作，对于set方法也是一致的，只有某一个线程第一次调用`get`或set才会对其进行初始化操作。

然后通过`set`方法，可以确定`threadlocalmap`的key是线程的引，只有第一次调用才会去创建`map`。`get`方法的初始化在`map`创建后，会用`null`作为值，没创建调用`createmap`构建`ThreadLocalMap`。

综上，可以看出值是存储在`ThreadLocalMap`中，而这个值维护在`Thread`中，而不是将值存在`ThreadLocal`里面，这只是做了个引用。

`ThreadLocalMap`本身是由Entry数组构成的

### key的取值

这个和斐波那契散列有关，然后int的取值在32位和64位的jvm上都是32位的试下，所以这个值是`2654435769`，换成十六进制就是`0x61c88647`，相当于每次增加这个值。

对于key冲突，则使用线性探测法进行解决。

### 内存泄漏

因为`ThreadLocal`是以类本身作为`key`存入`ThreadLocalMap`中，`ThreadLocalMap`的`Entry`在源码上是一个`WeekRefrence`的修饰，是个弱引用，所以当一个使用`ThreadLoal`的线程使用结束，这个时候如果被`gc`，会出现`key`为`null`的情况，最后导致这个`ThreadLocal`容器一直都不会被回收。所以为了解决这个问题，`get`、`set`以及`remove`都会调用`expungeStaleEntry`清除`null`为键值的数据。

## Atomic类

### 原理

核心原理用`AtomicIntenger`来分析，其主要在初始化的利用`unsafe`类工具，使用`cas+volatile`来保证方法的原子操作，利用`objectFieldOffset`这个方法直接从内存中获取存储值的地址，从而直接获取导致，另外用`volatile`进行修饰以组织指令重排而强制让访问此变量的是顺序的。

```java
    // setup to use Unsafe.compareAndSwapInt for updates
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;
```

### AtomicStampedReference

`AtomicStampedReference`内部维护一个`Pair`类，通过此类内部`stamp`来表示修改状态，以此来解决ABA问题

```java
    private static class Pair<T> {
        final T reference;
        final int stamp;
        private Pair(T reference, int stamp) {
            this.reference = reference;
            this.stamp = stamp;
        }
        static <T> Pair<T> of(T reference, int stamp) {
            return new Pair<T>(reference, stamp);
        }
    }
```

### AtomicMarkableReference

同`AtomicStampedReference`一样内部维护了一个Pair类，但是用Boolean 值mark作为修改标识，只有两个版本，这知识降低了ABA问题发生的概率，但是不能彻底解决

```java
    private static class Pair<T> {
        final T reference;
        final boolean mark;
        private Pair(T reference, boolean mark) {
            this.reference = reference;
            this.mark = mark;
        }
        static <T> Pair<T> of(T reference, boolean mark) {
            return new Pair<T>(reference, mark);
        }
    }
```

## CopyOnWriteArrayList

应用于读多写少的环境中，根据类注释，可以直到在所有可变操作（add、set和remove）的时候是创建底层数组副本来实现的。

从源码来看，get操作是直接没有锁和同步操作的，操作的就是原始的数组。

`set`操作先用`ReentrantLock`来获取锁，然后拷贝原数组的备份，在其基础上进行修改，最后用`setArray`方法来替换原数组。`add`方法也类似，但是在数据增长方面，没有了扩容控制，而是使用了`Arrays.copyOf`直接返回一个数据加一的新数组。而从固定位置插入的方法则使用`System.arrayCopy`方法进行操作

## ConcurrentLinkedQueue

一个基于链表节点实现的无界线程安全队列。

当许多线程共享一个公共集合时，`ConcurrentLinkledQueue`是一个合适的选择。

迭代器是弱一致的，返回的元素反映了队列在迭代器创建时或创建后某个时刻的状态，它不抛出`ConcurrentModificationException`，并且可以与其他操作并发进行。包含在队列里面的元素都将被返回一次。

## BlockingQueue

BlockingQueue在处理一个操作不能被立即满足但是能在未来某个时刻被满足的四种情况：

1. 抛出异常
2. 返回特殊值
3. 阻塞当前线程的执行直到条件被满足
4. 在给定的最大时间内进行阻塞

![[assets/bc2fdba651ed77e12cc13eb860da5fa7_MD5.jpeg]]

`BlockingQueue`不接受null，有容量限制，主要实现生产者-消费者队列，但是还支持`Collection`接口，其实现是线程安全的，所有队列方法都使用内部锁或者其他并发控制方式；其本质上不支持任何的`colse`和`shutdown`操作。

内存一致性问题：将对象放入一个`BlockingQueue`的操作要发生在将对象从另一个线程中`BlockingQueue`移除操作之前

当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。

### ArrryBlockingQueue

由数组构成的有界阻塞队列。这是一个经典的“有界缓冲区”，其中固定大小的数组包含由生产者插入并由消费者提取的元素。容量一旦创建，就不能更改。将元素放入满队列的尝试将导致操作阻塞；从空队列中获取元素的尝试也将类似地阻塞。此类支持可选的公平策略，用于对等待的生产者和消费者线程进行排序。默认情况下，不保证此顺序。但是，在公平性设置为`true`的情况下构建的队列将按FIFO顺序授予线程访问权限。公平通常会降低吞吐量，但会降低可变性并避免饥饿。

对于并发的控制，使用`ReentrantLock`加上两个`Condition`条件控制的。在`put`和`take`操作的时候，都需要通过`ReentranLock`获取锁，最终调用实际的`enqueue`和`dequeue`，通过两个`condition`条件来传递信号。

```java
    /*
     * Concurrency control uses the classic two-condition algorithm
     * found in any textbook.
     */

    /** Main lock guarding all access */
    final ReentrantLock lock;

    /** Condition for waiting takes */
    private final Condition notEmpty;

    /** Condition for waiting puts */
    private final Condition notFull;
```

### LinkedBlockingQueue

双锁算法的变体。`putLock`和`takeLock`在等待操作时候需要条件，由`ReentrantLock`进行实现，依赖`count`字段作为原子维护，以避免在大多数情况下需要同时获取两个锁。 这其实相当于有两个`ReentrantLock`和两个`Contion`条件来共同实现保证状态

提供读者和写着的可见性：当元素入队时，`putLock`获取锁并更新`count`，后续的读者通过`putLock`或者`takeLock`获取入队节点的可见性，读者`n = count.get()`，这将获取前n个`Node`的可见性。

默认构建不设置大小，将会将`capacity`设置位`Integer.MAX_VALUE`，这也就相当于可以构建一个虚假意义的无界队列

```java
    /** Lock held by take, poll, etc */
    private final ReentrantLock takeLock = new ReentrantLock();

    /** Wait queue for waiting takes */
    private final Condition notEmpty = takeLock.newCondition();

    /** Lock held by put, offer, etc */
    private final ReentrantLock putLock = new ReentrantLock();

    /** Wait queue for waiting puts */
    private final Condition notFull = putLock.newCondition();
```

### PriorityBlockingQueue

这个不保证相同优先级的元素排序，如果需要排序，可以自定义辅助键来打破优先级。

由基于数组的二叉堆进行实现，用一个`ReentrantLock`锁来保护公共操作。在`resize`的时候，使用简单的自旋锁来保证`take`操作进行分配，这就避免了等待的消费者的一再等待随之而来的因素累积。

默认的情况下使用自然排序，也可以通过自定义类实现 `compareTo`方法来指定元素排序规则，或者初始化时通过构造器参数 `Comparator`来指定排序规则。

```java
private static final int DEFAULT_INITIAL_CAPACITY = 11;

private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

// tryGrow的扩容数据
int newCap = oldCap + ((oldCap < 64) ?
                       (oldCap + 2) : // grow faster if small
                       (oldCap >> 1));
```

在使用`tryGrow`方法扩容的时候，目前容量小于64，那么就是`2 * oldCap + 2`，大于64的时候就是原来的1.5倍。

# 线程池

使用线程池的好处：

1. 降低资源消耗
2. 提高响应速度
3. 提高线程的可管理性

线程池大小的确定（n为内核数量，超线程那种）：

- CPU密集型$n+1$：因为消耗的时cpu资源，应该尽可能的增加计算机资源
- IO密集型$2n$：需要进行的大量的io操作，cpu的压力小，应该尽可能的利用io效率

## Executor

## 基础

Executor接口并不是严格 要求异步执行，一般情况是任务在调用之外的线程中执行，许多Executor的实现对任务的调度情况加以限制。

执行的任务需要实现`Runable`和`Callable`接口。

主要由三部分构成：

1. 任务
2. Executor
3. 结果

阿里的开发建议上不允许使用`Executors`去创建线程池，原因如下：

1. `FixedThreadPool`和`SingleThreadExecutor`允许的等待队列是`Integer.MAX_VALUE`，会造成大量的线程堆积
2. `CachedThreadPool`和`ScheduleldThreadPool`允许创建为`Intreger.MAX_VALUE`数量的线程，极端环境下也能造成大量线程堆积

线程池解决了两个不同的问题：

1. 由于减少了每个任务的调用开销，它们通常在执行大量异步任务时提高了性能，并且它们提供了一种绑定和管理执行任务集合时消耗资源的方法
2. 维护一些基本统计信息

提供了了一下几个工厂方法，底层是基于`ThreadPoolExecutor`实现的：

1. `Executors.newCachedThreadPool`无界线程池，具有自动线程回收的功能。从源码上看，`corePoolSize`被设置为0，`maximumPoolSize`被设置为`Integer.MAX_VALUE` ，`keepalive`被设置为60，工作队列用`SynchronousQueue`实现。当提交的任务速度大于执行任务的速度时候，就会导致不断创建工作线程，最终导致cpu和内存资源耗尽。
2. `Executors.newFixedThreadPool`创建固定线程数量的线程池。从源码可以看出，`corePoolSize`和`maximumPoolSize`都是传入的`nThreads`，然后执行的`workQueue`是`LinkedBlockingQueue。`不推荐的原因是他的等待队列是默认构造的`LinkedBlockingQueue`并且`corePoolSize`和`maximumPoolSize`相等的原因，导致不可能存在任务队列满的情况，`keepAliveTime`被设置为0，等待队列默认数量是`Intger.MAX_VALUE`，极端情况下会占满整个`workQueue`，最后导致oom
3. `Executors.newSingleThreadExecutor`，从源码可以看出，`corePoolSize`和`maximumPoolSize`都是1，工作队列使用`LinkedBlockingQueue`来实现，`keepalive`被设置为0，所以也会和`Executors.newFixedThreadPool`一样造成oom

推荐使用`ThreadPoolExecutor`去创建线程池

## ThreadPoolExecutor

![[assets/f00dca3d59db045e681294563ce3c649_MD5.jpeg]]


### 构造

其构造原理比较简单，就是些赋值操作，但是以下参数比较重要

1. `corePoolSize`：定义了最小可以同时运行的线程数量
    
2. `maximumPoolSize`：线程池中允许的最大线程数量
    
3. `workQueue`：在执行当前任务前会判断是否达到最大线程数量，达到就被存放到队列中
    
4. `handler`：拒绝异常处理器，用于处理当前线程池达到最大执行容量，workqueue也满的情况
    
    这个接口有四个实现类，代表了四种处理策略，实现的四个类作为ThreadPoolExecutor的四个内部类
    ![[assets/b77a6904eff085aa652bec503a6a44fa_MD5.jpeg]]
    
    1. `AbortPolicy`：抛出`RejectedExecutionException`，这个是默认的拒绝测率
    2. `CallerRunsPolicy`：调用线程的`execute`方法执行代码，如果`executor`关闭，则丢弃任务
    3. `DiscardOldestPolicy`：丢弃最早未处理的线程
    4. `DiscardPolicy`：不处理新任务，直接丢弃

对于可伸缩的应用程序，最好使用`CallerRunsPolicy`策略。

### 原理

使用`ReentrantLock`作为全局锁来控制并发

在一个新任务提交时，运行的`corePoolSize`小于`corePoolSize`时，即使其他任务存在空闲，一个新线程将被创建用于执行该任务。当运行的线程数大于`corePoolSize`小于`maximumPoolSize`时，则只会在`workQueue`满的时候才会创建新的线程。

默认情况下，即使是核心线程也只在新任务到达时初始创建和启动，但是可以使用`prestartCoreThread`或`prestartAllCoreThread`方法动态覆盖。

默认使用`ThreadFactory`创建新线程。如果未另行指定，则使用`Executors.defaultThreadFactory`，它创建的所有线程都位于同一`ThreadGroup`中，并且具有相同的`NORM_PRIORITY`优先级和非守护进程状态。

可以阅读`ThreadPoolExecutor`的`execute`的代码，在开头的注释中，将整个执行过程分成了三个步骤：

1. 如果正在运行的线程少于`corePoolSize`，则调用`addWorker(command,true)`增加一个线程，并使用此线程运行任务
2. 任务已经排队成功，也就是运行任务数量大于`corePoolSize`，则先要判断当前线程池是否关闭，然后还得再次获得线程池状态，如果线程池不是`RUNNING`状态则要从任务队列中移除任务，还得检查线程是否全部执行完毕，同时执行拒绝操作，还得检查线程池是否为空，为空则增加线程
3. 无法将任务放入队列，则尝试使用`addWorker`添加一个线程，如果失败通过`reject()`执行相应的拒绝策略

## 常见对比

### `Runable`和`Callable`

`Runable`不返回结果或抛出检查异常

`Callable`返回结果和异常

### `execute`和`submit`

`execute`用于提交不需要返回值的任务，所以无法判断任务是否呗线程池执行与否

`submit`用于提交需要返回值的任务，线程池会返回一个`Future`对象

### `shutdown`和`shutdowNow`

**`shutdown（）`** :关闭线程池，线程池的状态变为 `SHUTDOWN`。线程池不再接受新任务了，但是队列里的任务得执行完毕。

**`shutdownNow（）`** :关闭线程池，线程的状态变为 `STOP`。线程池会终止当前正在运行的任务，并停止处理排队的任务并返回正在等待执行的 `List<Runable>`，除了尽力尝试停止处理正在积极执行的任务之外，没有其他保证。此实现通过`Thread.interrupt`取消任务，因此任何无法响应中断的任务都可能永远不会终止。

## ScheduledThreadPoolExecutor

![[assets/6a719742f592fab8fcfbc108c04e9850_MD5.jpeg]]


主要用来在给定的延迟后运行任务，或者定期执行任务。但是在实际业务中，会使用Quartz等调度框架。

### 原理

此类通过以下方式实现`ThreadPoolExecutor`：

1. 使用自定义类型的`ScheduledFutureTask`
2. 使用自定义无界`DelayQueue`的变种`DelayedWorkQueue`，与`ThreadPoolExecutor`相比，`corePoolSize`和`maximumPoolSize`相同有效简化了一些相同的执行机制
3. 支持可选的关机后运行参数
4. 允许拦截和插装的任务修饰方法

在构造方面，`corePoolSize`是传入的构造，`maximumPoolSize`则是被设置为`Integer.MAX_VALUE`，`keepalive`为0，这就导致了在极端情况下，也就是提交任务的速度一直大于线程池中执行线程的速度，就会一直新增工作线程，导致耗尽系统资源。

使用`DelayedWorkQueue`作为任务的排队队列，是一个基于堆的数据结构，每个`ScheduledFutureTask`还要将其索引记录到堆数组中

### 执行过程

1. 当调用`scheduleAtFixedRate`方法时，会构建一个`ScheduledFutureTask`对象并添加到`DelayedWorkQueue`中，期间使用`decorateTask`将其转换成`RunnableScheduledFuture`对象
2. 使用`delayedExecute`获取`DelayedWorkQueue`中的任务，然后执行