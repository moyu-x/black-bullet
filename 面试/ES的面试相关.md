## 倒排序索引

![[assets/ec044b55230ef0c6586d197920f0a967_MD5.jpeg]]

倒排序索引由两个部分组成：

- 单词文件
- 倒排文件

搜索过程：

1. 对用户输入的数据进行分词，得到用户要搜索的所有词条
2. 然后用这些词去单词字典中进行匹配，找到对应的文档编号
3. 根据这些文档编号去取文件

创建倒排索引的步骤：

1. 创建文档列表：对原始数据进行编号，es中的_id就是
2. 创建索引列表：对文档中的数据进行分词，得到词条。对词条进行编号创建索引，然后记录下该词条包含的所有文档编号信息。

倒排索引的不变性有几个好处：

- 因为索引不能更新，不需要锁
- 文件系统缓存亲和性，由于索引不会改变，只要系统内存足够，大部分读请求直接命中内存，可以极大提高性能
- 其他缓存，如filter缓存，在索引的生命周期内始终有效
- 写入单个大的倒排索引允许数据被压缩，减少磁盘I/O和需要被缓存到内存的索引的使用量

## segment文件的合并流程

当我们往 ElasticSearch 写入数据时，数据是先写入 memory buffer，然后定时（默认每隔 1s）将 memory buffer 中的数据写入一个新的 segment 文件中，并进入 Filesystem cache（同时清空 memory buffer），这个过程就叫做 refresh；

 ElasticSearch 有一个后台进程专门负责 segment 的合并，定期执行 merge 操作，将多个小 segment 文件合并成一个 segment，在合并时被标识为 deleted 的 doc（或被更新文档的旧版本）不会被写入到新的 segment 中。合并完成后，然后将新的 segment 文件 flush 写入磁盘；然后创建一个新的 commit point 文件，标识所有新的 segment 文件，并排除掉旧的 segement 和已经被合并的小 segment；然后打开新 segment 文件用于搜索使用，等所有的检索请求都从小的 segment 转到大 segment 上以后，删除旧的 segment 文件，这时候，索引里 segment 数量就下降了。

segment 合并的过程，需要先读取小的 segment，归并计算，再写一遍 segment，最后还要保证刷到磁盘。可以说，合并大的 segment 需要消耗大量的 I/O 和 CPU 资源，同时也会对搜索性能造成影响。

## 三种分页

### from+size

优点：支持随机翻页
缺点：
1. 受到max_result_window的限制(默认一万)，不能无限分页
2. 存在深度分页的问题，往后越来越慢
### search after

search_after 查询**本质**：使用前一页中的一组排序值来检索匹配的下一页。

使用 search_after 要求后续的多个请求返回与第一次查询相同的排序结果序列。也就是说，即便在后续翻页的过程中，可能会有新数据写入等操作，但这些操作不会对原有结果集构成影响。

优点：可以无限翻页
缺点：只支持向后翻页，不支持随机翻页

### scroll遍历查询

优点：支持全量遍历
缺点：越往后的的查询，响应速度会更慢，因为其本身的索引不作为热点在内存中，需要从硬盘中加载


## 高并发中保证读写一致性

1、对于更新操作：可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，文档中有_version这个记录版本的乐观锁
2、对于写操作：一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
3、对于读操作：可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。

## 建立索引阶段如何优化

（1）如果是大批量导入，可以设置 index.number_of_replicas: 0 关闭副本，等数据导入完成之后再开启副本  
（2）使用批量请求并调整其大小：每次批量数据 5–15 MB 大是个不错的起始点。  
（3）如果搜索结果不需要近实时性，可以把每个索引的 index.refresh_interval 改到30s  
（4）增加 index.translog.flush_threshold_size 设置，从默认的 512 MB 到更大一些的值，比如 1 GB  
（5）使用 SSD 存储介质  
（6）段和合并：Elasticsearch 默认值是 20 MB/s。但如果用的是 SSD，可以考虑提高到 100–200 MB/s。如果你在做批量导入，完全不在意搜索，你可以彻底关掉合并限流。