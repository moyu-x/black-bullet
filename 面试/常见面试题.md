# 网络

## TCP协议中的半包，粘包问题具体是如何发生的，能否给我一个具体的例子？

主要原因是tcp协议是流式协议，并且还有MTU的原因
**粘包**：接到一个包，包内的数据是一个完整的数据加上另外一份数据的一部分，或者是多个完整数据
**半包**：接收到一个包，之包含数据的一半

解决办法：

1. 固定数据包的长度，剩下的进行填充，在netty中可以使用`FixedLengthFrameDecoder`
2. 指定字符串结尾，比如`\r\n`，在netty中可以使用`DelimiterBasedFrameDecoder`
3. 消息拆分成（包头+包格式）
	1. 一个是在消息头的option字段中，指定好长度这些信息
	2. 另外一个就是自定义下编解码的方式

ref:
1. [CppGuide/articles/网络编程/TCP协议如何解决粘包、半包问题.md at master · balloonwj/CppGuide](https://github.com/balloonwj/CppGuide/blob/master/articles/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/TCP%E5%8D%8F%E8%AE%AE%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%B2%98%E5%8C%85%E3%80%81%E5%8D%8A%E5%8C%85%E9%97%AE%E9%A2%98.md)
2. [Netty如何解决粘包以及拆包问题客户端与服务端进行TCP网络通信时，在发送以及读取数据时可能会出现粘包以及拆包问题，那 - 掘金](https://juejin.cn/post/6975109908106575903)

## TCP协议中滑动窗口的作用？它的调整是如何影响网络传输性能的？

ringbuffer，可以理解为一个环形队列，从网卡中收到的数据写入一个定长环形队列中，然后上层网络层按照固定的开窗大小从队列中读取数据。其本身还能允许一次性发送多个包到接收端而不应答，直到数据包处理后才进行应答。
- 写入数据的速度大于读取速度的时候就会导致丢包，然后引起网络重传。
- 写入数据小于读取速度的时候，就会造成等待。

可以调整的地方有两个，就是队列的大小（其本质其实是内存中映射的一个用于缓存的数据大小），另外一个就是读取的开窗。

有两个主要的控制：

- 流量控制：调整**通信双方**的数据传输速率，避免接收方出现缓存溢出问题
- 拥塞控制：调整**整个网络**中的数据传输速率，避免网络出现拥塞和丢包现象。这个主要的就是部署梯子都会开启的bbr算法

ref: 
- [TCP拥塞控制 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6)
- [4.2 TCP 重传、滑动窗口、流量控制、拥塞控制 | 小林coding](https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3)
- [TCP协议详解之滑动窗口，快速重传，流量控制与阻塞控制_tcp滑动窗口的作用-CSDN博客](https://blog.csdn.net/m0_74209411/article/details/136680494)

## TCP 协议中，数据有序性如何保证？

UDP是无序的，TCP是有序的，但是在网络传输(物理层面)是无序的，所以在接收端需要实现有序。

这个主要体现在TCP协议定义的包头的前80个字节中，其中有传输的包的序号，并且有保证包数据完整性的校验。接收端收到数据后，根据tcp协议头中的顺序进行组包，然后在进行完整性校验。

并且这个序号，在TCP连接建立后，就是递增的。

ref: 
- [网络协议 TCP 如何保证数据的有序无误传输_tcp通信一定是按顺序的吗-CSDN博客](https://blog.csdn.net/u013179982/article/details/113088429)
- [TCP/IP 协议-05-TCP 如何保证传输的可靠性 reliability | Echo Blog](https://houbb.github.io/2019/04/05/protocol-tcp-ip-06-tcp-handshake)

## 描述HTTP中会话的概念。如何使用Cookie或其他机制实现会话管理？有状态与无状态会话的优缺点是什么

### session的概念

根据维基百科的定义，通信设备（或人机）之间的一次session是指一次半持久性（semi-permanent）的信息交换，也称为一次对话，一次会话，一次会议等。其中半持久性是指一个session会在某个时间点建立连接，又会在某个时间点断开连接。

而 HTTP 的 session :通信设备之间，建立连接进行通信的过程都可以称之为session，其中通信过程中的历史状态信息即为session信息。
在web应用中，一次HTTP session就是关联同一个用户的一系列的客户端与服务器之间的网络请求-响应事务集合。

### cookie

cookie 是一种客户端会话技术, cookie 由服务端产生, 它是服务器存放在浏览器的一小份数据, 浏览器以后每次访问该服务器的时候都会将这小份数据携带到服务器去。

服务端创建 cookie, 将 cookie 放入响应对象中, Tomcat 容器将 cookie 转化为 set-cookie 响应头, 响应给客户端

客户端在收到 cookie 的响应头时, 在下次请求该服务的资源时, 会以 cookie 请求头的形式携带之前收到的 Cookie

### session 的有无状态

区别就是记录的位置（服务端是否记录状态信息 ）以及记录时间的长短

**无状态Session**是一种不会持久保存用户会话状态的对象，每次请求结束都会重新创建一个Session对象，因此无状态Session的会话状态是临时的。无状态Session指的是Session数据存储在客户端，而不是存储在服务器端

**有状态Session**指的是Session数据存储在服务器端，而不是存储在客户端。在有状态Session中，客户端和服务器之间的每个请求都需要包含Session ID

有状态的性能好，但是安全性比较低，因为session 信息存储在本地容易被破解。无状态因为 session 信息存储在服务端，安全性来说高一些，然后可以方便的迁移到多个服务器中，让服务端好进行扩展。

ref:

- [1.2 Session概念 · HTTP Sessions教程](https://ligexiao.gitbooks.io/http-sessions/content/11-session.html)
- [会话管理Cookie和Session](https://blog.csdn.net/2301_77193348/article/details/141036384)
- [无状态session和有状态session和JWT - 知乎](https://zhuanlan.zhihu.com/p/637004661)

## epoll和poll,select的区别

**select** 实现多路复用的方式是，将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，使用粗暴的遍历所有文件描述符的方式，检查到有 socket 可读或者可写的时候就标记，然后返回到用户态中。其本身使用一个`BitsMap`来存储，其本身存储长度是受限的，默认应该是 1024，超过就会提示`too many open files`

**poll** 模型和 select 的原理一模一样，只是使用动态数组以链表的方式存储管理的文件描述符，最终只会受到系统的文件描述符的上限限制。

`epoll`：

1. 使用了时间驱动机制，内核维护了一个链表来记录就绪事件，当有时间需要处理的时候，就进入到这个就绪队列中，只会返回事件发生的文件描述符的个数
2. 在内核里面维护了需要进行事件跟踪触发的文件描述符（红黑树）

	水平触发(LT)：当发生可读事件的时候，**服务端不断的从 epoll_wait 中苏醒，直到内核缓冲区被 read 函数读完才结束**
	边缘触发(ET)：当有可读事件发生的时候**服务器端只会从 epoll_wait 中苏醒一次**，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次

ref:
- [9.2 I/O 多路复用：select/poll/epoll | 小林coding](https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84-socket-%E6%A8%A1%E5%9E%8B)

## 零拷贝

其本身是一种`I/O`的操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。只有在支持 NIO 和 Epoll 传输时才能使用该特性。

### 主要的实现方式

1. mmap+write
2. sendfile
3. splice

## IO多路复用

多个请求服用同一个进程进行处理的方式，这就是多路复用 。
允许同一个进程同时监控多个文件描述符号（也就是网络套接字）

## dns

![[assets/489870cc3140c46e96ba76803079ab5b_MD5.jpeg]]

从dns读取的packet中可以明显看到，其本身是一个udp的协议（虽然现在也有DoH或者DoT），发送的时候全送query指令，响应则是会记录他的IP地址，类型，ttl时间


# 编程

## 伪共享、CPU亲和性Affinity

**伪共享**：当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。
	（现代cpu内部的多级缓存）存在着么一个对象，有a、b两个属性，线程1在修改a，线程b在读取b，当线程1修改a成功时候，此时线程2会发现数据已经被修改缓存失效，需要重新从主存中读取数据到缓存中，这就是需要重新加载原有对象到缓存中
	同时修改一个对象的同一个属性也会存在此问题

避免伪共享的主要思路就是让不相干的变量不要出现在同一个缓存行中

Java8之前就需要通过long类型去填充，之后可以考虑使用注解

**CPU亲和性：**

就是将某个进程/线程绑定到某个CPU core上，使其尽量长时间的运行而不被迁移到其他核心上。

现代cpu因为有超线程，所以在绑定核心的时候需要绑定到属于这个物理核心的两个对应core上

因为现代服务器都是使用numa架构的，所以还可以利用numa节点间缓存总线时间短的情况，在绑定cpu的时候，直接绑定到最近的两个cpu core上，达到缓存利用的最大化。

为了保证一些特殊的业务高性能的情况，可以直接独占一个cpu core，但是千万不要独占cpu0，或者使cpu0达到百分百使用，这是因为linux的系统调度在cpu0上，如果cpu0被完全占用，真个系统就会假死，不会有任何日志和异常输出，系统就会停在这一个时刻。

这样绑定进程或者线程到cpu上面，其实cgroup v2就用了这些，但是主要是绑定而不是独占

ref:

- [面试官：什么是伪共享，如何避免？ - 彭旭锐 - 博客园](https://www.cnblogs.com/pengxurui/p/16907796.html)
- [cpu affinity 亲和性 | wangpifu](https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/)

## 协程是什么

协程是一种基于线程之上，但是比线程更加轻量级的存在，这种由程序来管理的轻量级线程就叫协程（并且在用户态执行）。

和Java的线程相比，Java的线程是基于pthread的库实现的，每一次线程切换都会发生系统的上下文切换，并且数量上限和性能受到系统限制。

此处python中有yeild，已经golang的gmp模型，gmp模型如下：

g: goroutine go的协程，参与调度的最小单位
m：machine 系统级别的协程
p：processor，逻辑处理器

![[assets/f510e3b90ff34816557414a9a69a30b7_MD5.jpeg]]

通过上图，可以看到，实际影响协程的性能的已经不是系统的上下文切换那些，毕竟都在用户抬进行运行，那实际影响协程调度的就是协程本身的调度算法了。

比如简单的可以发现如果其中一个对应p的等待队列是空的话，这个时候，其他线程就可以进行抢占。

所以调度算法的设计策略有如下几种：

- 复用线程
- 利用并行
- 抢占
- 全局G队列

ref:

- [notes/GoLang/golang大杀器GMP模型.md at main · fengyuan-liang/notes](https://github.com/fengyuan-liang/notes/blob/main/GoLang/golang%E5%A4%A7%E6%9D%80%E5%99%A8GMP%E6%A8%A1%E5%9E%8B.md)
- [[Golang三关-典藏版] Golang 调度器 GMP 原理与调度全分析 | Go 技术论坛](https://learnku.com/articles/41728)
- [调度机制概述 | 深入Go语言之旅](https://go.cyub.vip/gmp/gmp-model/)
- [一文读懂什么是进程、线程、协程 - 回首笑人间 - 博客园](https://www.cnblogs.com/Survivalist/p/11527949.html)
- [协程 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E5%8D%8F%E7%A8%8B)

## 如何实现高性能无所队列

无锁队列（Lock-Free Queue）是一种并发数据结构，它允许多个线程在没有锁的情况下进行并发操作。

无锁队列的设计目标是在保持线程安全的前提下提供高性能的并发操作。它通常使用 CAS（Compare and Swap）等原子指令来实现对队列头部和尾部指针的更新和操作

现在几乎所有的CPU指令都支持CAS的原子操作，X86下对应的是 `CMPXCHG` 汇编指令。

> 锁会引起以下三个问题： 1）频繁线程抢占，导致cache损坏 / 失效。 2）在同步机制上争抢队列，导致任务将大量的时机浪费在获取保护队列数据的互斥锁，而不是处理队列中的数据。 3）多线程场景下的动态内存分配，会阻塞所有这个任务共享地址空间中的其他任务。

一些实现的伪代码：

初始化的代码，这个比较简单：

```c
InitQueue(Q)
{
    node = new node()
    node->next = NULL;
    Q->head = Q->tail = node;
}
```

后续主要的是如何实现入队(enqueue)，这里的操作就需要cas操作，下面描述基于单向队列：

### 入队操作

1. 检查队列是否已满
2. 尝试使用CAS操作将队位指针向前移动一个位置，从而预留出空间来存储新元素
	1. 如果此处尝试使用for循环来调用cas操作，就会造成死循环。因为当前线程入队在同一个节点，另外一个线程已经成功，这个时候cas就返回失败重试，当劣化的情况下，会一直失败导致死循环。
	2. 最优的方式是：
		1. 先去一下尾部的指针和尾部指针的next
		2. 对尾的指针被移动，则重新开始
		3. 如果对于位指针的next部位null，则fetch全局尾指针到next（用cas操作进行），重新开始
		4. 加入节点成功就结束（这里也是用cas操作）

### 出队操作

1. 检查队列是否为空
2. 读取元素并删除：这个时候就直接使用cas操作反复读取就行，这里有个注意的电视取的是head本身的next，这是一个边界问题，避免队列头和队列尾是同一个元素。在非高性能队列的情况可能影响不大，但是对于使用cas操作的话这样会一直互斥下去。

### CAS的BBA问题

1. 进程P1在共享变量中读到值为A
2. P1被抢占了，进程P2执行
3. P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占。
4. P1回来看到共享变量里的值没有被改变，于是继续执行。

加个计数器，或者double-cas


